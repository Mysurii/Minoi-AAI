{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net From Scratch\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    @staticmethod\n",
    "    def f(x):\n",
    "        return x\n",
    "    @staticmethod\n",
    "    def df(x):\n",
    "        return x\n",
    "\n",
    "class Relu():\n",
    "    @staticmethod\n",
    "    def f(x):\n",
    "        return x * (x > 0)\n",
    "    @staticmethod\n",
    "    def df(x):\n",
    "        return 1 * (x > 0)\n",
    "\n",
    "class Sigmoid():\n",
    "    @staticmethod\n",
    "    def f(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    @staticmethod\n",
    "    def df(x):\n",
    "        return Sigmoid.f(x) * (1 - Sigmoid.f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE():\n",
    "  @staticmethod\n",
    "  def f(target, output):\n",
    "    return np.mean((target - output) **2)\n",
    "  \n",
    "  @staticmethod \n",
    "  def df(target, output):\n",
    "    return 2 * (target - output) / np.size(output)\n",
    "\n",
    "class Crossentropy():\n",
    "  @staticmethod\n",
    "  def f(target, output):\n",
    "    return np.mean(-target * np.log(output) - (1 - target) * np.log(1 - output))\n",
    "  \n",
    "  @staticmethod \n",
    "  def df(target, output):\n",
    "    return ((1 -  target) / (1 - output) - target/output) / np.size(target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, neurons, activation=Linear):\n",
    "        self.neurons = neurons\n",
    "        self.activation = activation\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        self.lr = 0.02 # Snelheid waarmee de model traint -> staat nu hardcoded\n",
    "\n",
    "    def initialize(self, prev_neurons):\n",
    "        self.weights = np.random.normal(0.0, 1.0, (self.neurons, prev_neurons))\n",
    "        self.biases = np.random.normal(size=(self.neurons, 1))\n",
    "\n",
    "    def feed_forward(self, input_array):\n",
    "        # Input en output opslaan -> zijn nodig voor gradient descent\n",
    "        self.inputs = input_array \n",
    "\n",
    "        # Y = W * I + B (matrix * vector)\n",
    "        self.output = self.activation.f(np.dot(self.weights, self.inputs) + self.biases) \n",
    "        return self.output\n",
    "\n",
    "    def gradient_descent(self, errors):\n",
    "        delta_weights = self.lr * np.dot((errors * self.activation.df(self.output)), self.inputs.T)\n",
    "        delta_biases = self.lr * errors * self.activation.df(self.output)\n",
    "\n",
    "        self.weights = np.add(self.weights, delta_weights)\n",
    "        self.biases = np.add(self.biases, delta_biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurale netwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        # Initialiseer de laag met weights en biases alleen als het niet de input laag is.\n",
    "        if len(self.layers) > 0:\n",
    "            prev_neurons = self.layers[-1].neurons\n",
    "            layer.initialize(prev_neurons)\n",
    "        \n",
    "        self.layers.append(layer)\n",
    "        \n",
    "\n",
    "    def predict(self, input_array, transposed = False):\n",
    "        \n",
    "        output = input_array\n",
    "        \n",
    "        if not transposed:\n",
    "            output = output.T\n",
    "\n",
    "        for lay in self.layers[1:]:\n",
    "            output = lay.feed_forward(output)\n",
    "        return output\n",
    "\n",
    "    def fit(self, X_values: np.ndarray ,y_true: np.ndarray, loss_function=MSE, epochs=10):\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            sum_errors = 0\n",
    "\n",
    "            for x, y in zip(X_values, y_true):\n",
    "                \n",
    "                # feedforward\n",
    "                prediction = self.predict(x.reshape(-1,1), transposed = True) # Reshape maakt ndmin 2 en transposed het al\n",
    "\n",
    "                # print('prediction:')\n",
    "                # print(prediction)\n",
    "                # print('y')\n",
    "                # print(y)\n",
    "\n",
    "\n",
    "                sum_errors += loss_function.f(y, prediction) # houdt mse bij om het te visualiseren\n",
    "\n",
    "                error = np.array(loss_function.df(y, prediction), ndmin=2) # gebruik afgeleide om weten of we de gewichten moeten verhogen of verlagen\n",
    "                #error = y - prediction\n",
    "                #sum_errors += cross_entropy(y, prediction[0][0]) # houdt mse bij om het te visualiseren\n",
    "             \n",
    "                \n",
    "                # backward propagation\n",
    "                # error = mse_derivative(y, prediction)\n",
    "\n",
    "                for lay in reversed(self.layers[1:]):\n",
    "                    lay.gradient_descent(error)\n",
    "                    error = np.dot(lay.weights.T, error)           \n",
    "            sum_errors /= len(X_values)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "            print(f\"Error: {sum_errors}\\n\")\n",
    "        print(f\"\\nFinished Training\\n{'=' * 50}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "Getallen optellen\n",
    "\n",
    "e.g. array van [0.23, 0.56] = 0.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Error: 0.0364985504131815\n",
      "\n",
      "Epoch 2/10:\n",
      "Error: 0.005417132595421775\n",
      "\n",
      "Epoch 3/10:\n",
      "Error: 0.0026162492924910845\n",
      "\n",
      "Epoch 4/10:\n",
      "Error: 0.0014008464191218222\n",
      "\n",
      "Epoch 5/10:\n",
      "Error: 0.0008065960335853603\n",
      "\n",
      "Epoch 6/10:\n",
      "Error: 0.0005114180166782833\n",
      "\n",
      "Epoch 7/10:\n",
      "Error: 0.00034643069548445947\n",
      "\n",
      "Epoch 8/10:\n",
      "Error: 0.00024538778006405465\n",
      "\n",
      "Epoch 9/10:\n",
      "Error: 0.00018177276061855506\n",
      "\n",
      "Epoch 10/10:\n",
      "Error: 0.00013980369055809048\n",
      "\n",
      "\n",
      "Finished Training\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from random import random, seed\n",
    "\n",
    "seed(42)\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.add(Layer(2, activation=Relu))\n",
    "nn.add(Layer(5, activation=Relu))\n",
    "nn.add(Layer(1, activation=Relu))\n",
    "\n",
    "X = np.array([[random() for _ in range(2)] for _ in range(1000)])\n",
    "y = np.array([i[0] + i[1] for i in X])\n",
    "\n",
    "nn.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.86084197, 72.29730881,  0.80161378,  0.58970399,  0.22825553,\n",
       "         0.99183532,  0.49839215]])"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = np.array([[3, 8], [50, 32],[0.4, 0.4], [0.27, 0.32], [0.1, 0.13], [0.76, 0.22], [0.2, 0.3]]) # 11, 82, 0.8, 0.59, 0.23, 0.98\n",
    "nn.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# we gebruiken .values om een Numpy array te krijgen in plaats van een Pandas DataFrame\n",
    "X_iris = iris.drop('species', axis=1).values\n",
    "X_iris = np.array([*X_iris[:50], *X_iris[100:150]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_iris = iris['species'].values\n",
    "y_iris = np.array([*y_iris[:50], *y_iris[100:150]], ndmin=2).T \n",
    "# y_iris = y_iris.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4), (100, 1))"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_iris.shape, y_iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aliozcan/miniforge3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "encoded_y_iris = le.fit_transform(y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, encoded_y_iris, test_size=0.2, stratify=y_iris, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Error: 0.17960842395927373\n",
      "\n",
      "Epoch 2/10:\n",
      "Error: 0.0006412768407971352\n",
      "\n",
      "Epoch 3/10:\n",
      "Error: 0.00025289813255518074\n",
      "\n",
      "Epoch 4/10:\n",
      "Error: 0.0001446324352972104\n",
      "\n",
      "Epoch 5/10:\n",
      "Error: 9.473175642752612e-05\n",
      "\n",
      "Epoch 6/10:\n",
      "Error: 6.917426980940955e-05\n",
      "\n",
      "Epoch 7/10:\n",
      "Error: 5.157290588180118e-05\n",
      "\n",
      "Epoch 8/10:\n",
      "Error: 4.024959485563963e-05\n",
      "\n",
      "Epoch 9/10:\n",
      "Error: 3.2140045651976645e-05\n",
      "\n",
      "Epoch 10/10:\n",
      "Error: 2.6279689521322828e-05\n",
      "\n",
      "\n",
      "Finished Training\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "model = NeuralNetwork()\n",
    "\n",
    "model.add(Layer(4, activation=Relu))\n",
    "model.add(Layer(7, activation=Relu))\n",
    "model.add(Layer(1, activation=Sigmoid))\n",
    "\n",
    "X_train\n",
    "\n",
    "# X = np.array([[random() for _ in range(2)] for _ in range(1000)])\n",
    "# y = np.array([[i[0] + i[1]] for i in X])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, loss_function=MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1]\n",
      "[1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1]\n",
      "\n",
      "accuracy score: 1.0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "print(y_test.tolist())\n",
    "print([round(x) for x in pred[0]])\n",
    "\n",
    "rounded_predictions = np.array([round(x) for x in pred[0]])\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f\"\\naccuracy score: {accuracy_score(y_test, rounded_predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "055079195073658a51114928e756d4a43022fc1e84eb762010fcf721cf3a9eca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
